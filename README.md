# bert-research

### BERT: Pre-training of Deep Bidirectional Transformers forã€€Language Understanding
### How to Fine-Tune BERT for Text Classification?
### ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS
### DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter
### MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices

https://docs.google.com/presentation/d/1esE-50R0eZb1X0gO2WtugBnO1sOQSncj1srsvPZSPCE/edit?usp=drive_link

